---
name: scrape_company_pipeline
description: Scrape pharmaceutical company pipeline data from company websites using Playwright MCP to extract drug programs not yet in ClinicalTrials.gov (preclinical, discovery) and company-specific status updates
category: data_collection
complexity: high
servers:
  - playwright_mcp
patterns:
  - web_scraping
  - mcp_integration
  - html_parsing
  - auto_detection
  - snapshot_capture
therapeutic_areas:
  - all
output_format: json
requires_setup: true
setup_doc: INSTALLATION.md
created: 2025-01-24
version: 1.0.0
---

# Company Pipeline Web Scraper

## Overview

Automatically extract drug pipeline data from pharmaceutical company websites using Microsoft's Playwright MCP server. This skill captures programs not yet in public databases (preclinical, discovery phase) and provides company-specific status updates before official announcements.

**Architecture**: Uses Playwright MCP server for browser automation with **PDF-first scraping strategy**. If PDF available, parse PDF for study-level data; if not, fallback to web scraping.

**Execution Pattern**: This skill uses **direct MCP tool execution** - NO pharma-search-specialist agent invocation. Main Claude Code agent executes Playwright MCP tools directly. See `AGENT_PATTERN.md` for detailed execution flow.

**Key Value**:
- **Gap filling**: Preclinical and discovery programs not in ClinicalTrials.gov
- **Company perspective**: Internal status, strategic focus, nomenclature
- **Early signals**: Latest pipeline changes before press releases
- **BD intelligence**: Identify early-stage assets for licensing/acquisition

**Challenge**: Most modern pharma websites use JavaScript rendering (React, Angular), requiring browser automation (not simple HTTP requests).

## Features

### 1. PDF-First Scraping Strategy
- **Primary Method**: PDF parsing when pipeline PDF is available
- **Study-Level Data**: Captures study numbers (101, 201, 303-JP) from PDFs
- **Official Source**: PDFs are authoritative company documents
- **Fallback**: Web scraping when no PDF available
- **Automatic Detection**: Checks for PDF links before scraping

### 2. Comprehensive Data Extraction
- **PDF Parsing**: Study numbers, regional submissions, complete program data
- **Web Scraping**: Molecule names, indications, phases, mechanisms (when PDF unavailable)
- **Browser Automation**: Full JavaScript execution and rendering via Playwright MCP
- **DOM Extraction**: Uses `browser_evaluate` for structured data extraction

### 3. Data Quality
- **Deduplication**: Removes duplicate entries
- **Validation**: Filters suspicious/incomplete data
- **Normalization**: Standardizes fields across companies
- **Warning system**: Flags parsing issues

### 4. Configuration
- Pre-configured for 11+ major pharma companies
- Extensible company URL database (JSON config)
- Phase and therapeutic area mappings
- Rate limiting and polite scraping

## Input Schema

```python
scrape_company_pipeline(
    company: str,                          # Required: "Pfizer", "BeOne Medicines", etc.
    scrape_config: Optional[Dict] = {
        "include_preclinical": bool,       # Include discovery/preclinical (default: True)
        "include_approved": bool,          # Include marketed drugs (default: False)
        "therapeutic_areas": List[str],    # Filter by TA (default: all)
        "min_phase": str                   # Minimum phase (default: "Discovery")
    },
    output_options: Optional[Dict] = {
        "format": str,                     # "json", "csv" (default: "json")
        "include_metadata": bool,          # Include scrape timestamp (default: True)
        "deduplicate": bool                # Remove duplicates (default: True)
    }
)
```

## Output Schema (v2.0 - Study-Level Granularity)

```python
{
    "company": str,
    "scrape_metadata": {
        "scraped_at": str,              # ISO timestamp
        "source_url": str,              # Pipeline page URL
        "scraper_version": str,         # Version
        "strategy_used": str,           # "playwright_mcp", "requests"
        "success": bool,
        "warnings": List[str],          # Any parsing issues
        "schema_version": str           # "2.0" for enhanced schema
    },
    "pipeline": [{
        "program_name": str,            # Drug/molecule name (e.g., "Sonrotoclax")
        "study_number": str,            # Study identifier (e.g., "101", "303-JP")
        "indication": str,              # Target disease
        "therapeutic_area": str,        # Oncology, CNS, etc.
        "phase": str,                   # "Discovery", "Phase 1", etc.
        "mechanism": str,               # MOA (if available)
        "region": str,                  # Regional submission (JP, CN, US, EU)
        "notes": str                    # Additional details
    }],
    "summary_stats": {
        "total_programs": int,          # Individual studies count
        "by_phase": Dict[str, int],     # {"Phase 1": 42, "Phase 2": 12, ...}
        "by_therapeutic_area": Dict[str, int],
        "unique_molecules": int         # Distinct molecule count
    }
}
```

**Key Changes in v2.0:**
- **`study_number`**: Captures individual study identifiers (101, 201, 303-JP)
- **`region`**: Tracks regional submissions (Japan, China, US, EU)
- **`unique_molecules`**: Summary stat showing molecule count vs study count
- **Composite deduplication**: Uses (molecule + study_number + indication + phase) to prevent collapsing studies
- **Accuracy**: Achieves >90% match with official company PDFs

## Usage Pattern

### Direct Execution (Primary Method)

This skill uses **direct MCP tool execution** by main Claude Code agent. NO agent delegation required.

**User Query:**
```
Scrape BeOne Medicines pipeline
```

**Main Agent Execution:**
1. Read company URL from `config/company_urls.json`
2. Navigate to page: `mcp__playwright-mcp__browser_navigate(url)`
3. Check for PDF: `mcp__playwright-mcp__browser_network_requests()`
4. **If PDF found:**
   - Download and parse PDF with Python
   - Extract study-level data (study numbers, regions)
5. **If no PDF:**
   - Use `mcp__playwright-mcp__browser_evaluate()` for DOM extraction
   - Extract molecule/indication/phase data
6. Format and return structured results

**Output:**
```
‚úì Extracted 72 programs from BeOne Medicines pipeline
  Strategy: PDF Parsing (study-level data available)

By Phase:
  Phase 1: 42 programs
  Phase 2: 12 programs
  Phase 3: 10 programs
  Approved: 8 programs

Study Numbers Captured: 68 (94%)
Unique Molecules: 26
```

### Example 1: Single Company

**User:** "Get BeOne Medicines pipeline"

**Result:**
```json
{
  "company": "BeOne Medicines",
  "pipeline": [
    {
      "program_name": "Zanubrutinib",
      "indication": "CLL/SLL",
      "phase": "Approved",
      "therapeutic_area": "Hematologic Malignancies",
      "mechanism": "BTK Inhibitor"
    },
    ...28 total programs
  ],
  "summary_stats": {
    "total_programs": 28,
    "by_phase": {"Phase 1": 17, "Preclinical": 6, "BLA Filed": 3, "Approved": 2}
  }
}
```

### Example 2: Multi-Company Analysis

**User:** "Compare pipelines of Novo Nordisk, Pfizer, and Amgen"

**Main Agent Execution:**
1. Execute scraping for each company directly (no agent invocation)
2. Aggregate results
3. Perform comparative analysis

**Output:**
```
Pipeline Comparison:

Novo Nordisk: 45 programs (focus: Diabetes 44%, Obesity 22%)
Pfizer: 68 programs (focus: Oncology 35%, Vaccines 18%)
Amgen: 53 programs (focus: Oncology 42%, Inflammation 25%)

Key Insights:
- Novo Nordisk dominates metabolic disease space
- Pfizer has most diversified portfolio
- Amgen leads in biologics innovation
```

### Example 3: Therapeutic Area Deep Dive

**User:** "Find all GLP-1 programs across major pharma pipelines"

**Main Agent Execution:**
1. Scrape multiple company pipelines directly
2. Filter for GLP-1 mechanism
3. Aggregate and rank

**Output:**
```
GLP-1 Pipeline Landscape:

Novo Nordisk:
- Semaglutide (Approved) - Obesity, T2D
- NNC0480-0389 (Phase 3) - Obesity
- NN1738 (Phase 2) - MASH

Eli Lilly:
- Tirzepatide (Approved) - T2D, Obesity
- Retatrutide (Phase 3) - Obesity
- LY3437943 (Phase 2) - MASH

...7 companies with GLP-1 programs identified
```

## Setup

### Playwright MCP Installation

This skill requires Playwright MCP server to be configured in Claude Code.

**Status:** ‚úÖ Already configured in `.mcp.json`

See `INSTALLATION.md` for detailed setup instructions if needed.

**Quick Verification:**
```
# Check if Playwright MCP is available
mcp__playwright-mcp__browser_navigate("https://example.com")
```

**No Python Dependencies Required:**
- Uses Claude Code's MCP infrastructure
- No local Playwright installation needed
- No pip packages to install

## Configuration

Company URLs and selectors are configured in `config/company_urls.json`:

```json
{
  "companies": {
    "BeOne Medicines": {
      "pipeline_url": "https://beonemedicines.com/science/pipeline/",
      "scraper_type": "auto_detect",
      "last_verified": "2025-01-24"
    }
  },
  "phase_mappings": {
    "preclinical": "Preclinical",
    "phase i": "Phase 1",
    "approved": "Approved"
  }
}
```

**Adding new companies**: Add entry to `companies` section with pipeline URL.

## How It Works

### 1. Configuration Lookup
- Loads company configuration from `config/company_urls.json`
- Fuzzy matches company name (case-insensitive, substring matching)

### 2. Scraping Strategy Selection
- **react_spa**: Uses Playwright for JavaScript rendering
- **static_html**: Uses requests for simple pages
- **auto_detect**: Tries both with fallback

### 3. Intelligent Parsing
- Detects HTML tables with pipeline-like headers
- Finds div/article containers with pipeline classes
- Extracts program data from repeated elements

### 4. Data Normalization
- Standardizes phase names (company-specific ‚Üí standard)
- Maps therapeutic areas to standard categories
- Validates required fields

### 5. Quality Control
- Deduplicates based on (name, indication, phase)
- Filters suspicious entries (gibberish, missing data)
- Generates warnings for issues

## Output Examples

### Terminal Output

```
================================================================================
  BeOne Medicines Pipeline Summary
  Scraped: 2025-01-24T15:30:00Z
  Source: https://beonemedicines.com/science/pipeline/
================================================================================

Program                        Indication                     Phase
------------------------------ ------------------------------ ---------------
BMed-101                      Advanced Solid Tumors          Phase 1
BMed-102                      Hematologic Malignancies       Preclinical
BMed-103                      Metabolic Disease              Discovery

üìä Total Programs: 8

üìà By Phase:
  Phase 1                       2 programs
  Preclinical                   3 programs
  Discovery                     3 programs

‚ö†Ô∏è  Warnings (1):
  - BMed-104: Missing phase, defaulting to Unknown
```

### JSON Output

```json
{
  "company": "BeOne Medicines",
  "scrape_metadata": {
    "scraped_at": "2025-01-24T15:30:00Z",
    "source_url": "https://beonemedicines.com/science/pipeline/",
    "strategy_used": "requests",
    "success": true
  },
  "pipeline": [
    {
      "program_name": "BMed-101",
      "indication": "Advanced Solid Tumors",
      "phase": "Phase 1",
      "therapeutic_area": "Oncology",
      "mechanism": "Unknown",
      "notes": ""
    }
  ],
  "summary_stats": {
    "total_programs": 8,
    "by_phase": {
      "Phase 1": 2,
      "Preclinical": 3,
      "Discovery": 3
    }
  }
}
```

## Limitations & Considerations

### 1. Website Changes
**Problem**: Pharma companies frequently redesign websites, breaking selectors.
**Solution**: Auto-detect mode reduces brittleness. Update `company_urls.json` when needed.

### 2. Rate Limiting
**Problem**: Aggressive scraping can trigger rate limits or IP blocks.
**Solution**: Built-in 3-second delay. Use responsibly.

### 3. Legal Compliance
**Important**: Only scrapes publicly accessible pages. Respects robots.txt (user's responsibility).
**Attribution**: Source URLs included in output.

### 4. Data Completeness
**Reality**: Some companies provide minimal pipeline info on websites.
**Expectation**: Treat as supplementary to ClinicalTrials.gov, not replacement.

## Troubleshooting

### Issue: "Company not found in configuration"
**Fix**: Add company to `config/company_urls.json` or check spelling

### Issue: Empty pipeline returned
**Cause**: Page structure doesn't match auto-detect patterns
**Fix**: Inspect page with browser DevTools, add custom selectors to config

### Issue: "Playwright not installed" warning
**Fix**: Install with `pip install playwright && playwright install chromium`
**Alternative**: Use fallback - many pages work with simple requests

### Issue: Parsing errors
**Cause**: Unusual page structure
**Fix**: Check `warnings` in output for clues. Update parsing logic if needed.

## Future Enhancements

1. **Playwright MCP Integration**: Use Playwright MCP server for consistency
2. **Historical Tracking**: Store snapshots to track pipeline changes over time
3. **ML-based Extraction**: Train model to auto-detect table structures
4. **Multi-language Support**: Scrape non-English sites (China, Japan)
5. **API Wrappers**: For companies providing official APIs
6. **Selector Health Monitoring**: Weekly cron to test all scrapers

## References

- **Playwright**: https://playwright.dev/python/
- **BeautifulSoup**: https://www.crummy.com/software/BeautifulSoup/
- **Web Scraping Ethics**: https://toscrape.com/
- **robots.txt Specification**: https://www.robotstxt.org/

## Version History

- **1.0.0** (2025-01-24): Initial implementation with auto-detect parsing
