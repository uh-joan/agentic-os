# Scripts Organization Guide

This document describes the organization of analysis scripts and utilities in the agentic-os project.

## Directory Structure

```
agentic-os/
├── scripts/
│   ├── analysis/              # Analysis scripts (generated by pharma-search-specialist)
│   │   ├── obesity/           # Obesity clinical trials analysis
│   │   │   ├── obesity_pipeline_analysis.py
│   │   │   ├── obesity_active_pipeline_analysis.py
│   │   │   └── README.md
│   │   └── README.md
│   ├── mcp/                   # MCP client and server implementations
│   │   ├── client.py          # MCP client wrapper
│   │   └── servers/           # MCP server implementations
│   └── utils/                 # Utility scripts
│       ├── alternatives/      # Alternative implementation tests
│       │   └── fda_alternatives.py
│       └── fda_query_validator.py
├── data_dump/                 # Raw MCP query results (timestamped)
├── docs/                      # Documentation
│   ├── testing/               # Testing and development documentation
│   └── SCRIPTS_ORGANIZATION.md
└── temp/                      # Analytical agent outputs

```

## Analysis Scripts (`scripts/analysis/`)

Generated analysis scripts organized by therapeutic area.

### Current Scripts

**Obesity Pipeline Analysis:**
- `scripts/analysis/obesity/obesity_pipeline_analysis.py` - Full pipeline (all trials)
- `scripts/analysis/obesity/obesity_active_pipeline_analysis.py` - Active trials only

**Usage:**
```bash
# Run from project root
python3 scripts/analysis/obesity/obesity_pipeline_analysis.py

# Save to data_dump
mkdir -p data_dump/$(date +%Y-%m-%d)_obesity_pipeline
python3 scripts/analysis/obesity/obesity_pipeline_analysis.py > \
  data_dump/$(date +%Y-%m-%d)_obesity_pipeline/all_trials.txt
```

**Key Features:**
- Self-contained (all dependencies in script)
- Location-agnostic (can run from any directory)
- MCP-based (no direct API calls)
- Structured output with strategic insights

See `scripts/analysis/README.md` for details.

## MCP Infrastructure (`scripts/mcp/`)

Model Context Protocol client and server implementations.

### Client (`scripts/mcp/client.py`)

Wrapper for communicating with MCP servers via stdio:

```python
from mcp.client import get_client

client = get_client('ct-gov-mcp')
result = client.call_tool('ct_gov_studies', {
    'method': 'search',
    'condition': 'obesity',
    'status': 'recruiting',
    'location': 'United States',
    'pageSize': 10
})
```

**Key Functions:**
- `get_client(server_name)` - Get or create MCP client
- `call_tool(tool_name, arguments)` - Execute MCP tool
- `list_tools()` - List available tools

### Servers (`scripts/mcp/servers/`)

MCP server implementations for various data sources:
- `ct_gov_mcp/` - ClinicalTrials.gov API
- `fda_mcp/` - FDA drug labels and adverse events
- `pubmed_mcp/` - PubMed biomedical literature
- Additional servers configured in `.mcp.json`

## Utilities (`scripts/utils/`)

Helper scripts and validation tools.

### FDA Query Validator
`scripts/utils/fda_query_validator.py` - Automatic validation and optimization of FDA MCP queries.

**Auto-applied Rules:**
- Adds `count` parameter if missing (prevents 67k token responses)
- Adds `.exact` suffix to count fields
- Validates field selections
- Shows token savings (99.4% reduction)

### Alternatives
`scripts/utils/alternatives/` - Alternative implementations and tests for MCP functionality.

## Data Organization

### `data_dump/` - Raw MCP Results

Timestamped directories with raw query results:
```
data_dump/
└── YYYY-MM-DD_HH-MM-SS_tool_term/
    ├── query.json          # Original query parameters
    ├── results.json        # Raw MCP response
    ├── summary.md          # Human-readable summary
    └── metadata.json       # Execution metadata
```

**Example:**
```
data_dump/2025-11-18_obesity_pipeline/
├── all_trials.txt          # Full pipeline analysis
└── active_trials.txt       # Active trials analysis
```

### `temp/` - Analytical Outputs

Agent-generated analysis files:
```
temp/
├── epidemiology_analysis_YYYY-MM-DD_HHMMSS_condition.md
├── patient_flow_YYYY-MM-DD_HHMMSS_drug_indication.md
├── competitive_analysis_YYYY-MM-DD_HHMMSS_indication.md
└── [other analytical outputs]
```

## Documentation (`docs/`)

### Testing Documentation (`docs/testing/`)

Development and testing documentation:
- `ALTERNATIVES_TEST_RESULTS.md`
- `COMPREHENSIVE_MCP_TESTING_REPORT.md`
- `CRITICAL_BUGS_ANALYSIS.md`
- `FDA_OPTIMIZATION_SUMMARY.md`
- `FINAL_COMPREHENSIVE_TEST_REPORT.md`
- `MCP_ALTERNATIVES_SOLUTION.md`
- `MCP_TESTING_COMPLETE.md`
- `MCP_TESTING_FINAL_SUMMARY.md`
- `QUICK_FIXES_CHECKLIST.md`

## Script Generation Workflow

### Using pharma-search-specialist

**1. Invoke Agent:**
```
"You are pharma-search-specialist. Read .claude/agents/pharma-search-specialist.md.

Query: '[user query]'

Read relevant tool guide from .claude/.context/mcp-tool-guides/
Return ONLY JSON execution plan."
```

**2. Execute Plan:**
Agent returns Python code → Claude Code executes → saves to `data_dump/`

**3. Organize Generated Scripts:**
```bash
# Move to appropriate location
mv script_name.py scripts/analysis/[therapeutic_area]/

# Update sys.path in script
from pathlib import Path
script_dir = Path(__file__).resolve().parent
root_dir = script_dir.parent.parent.parent
sys.path.insert(0, str(root_dir / 'scripts'))
```

**4. Document:**
- Update `scripts/analysis/README.md`
- Create therapeutic area README if needed
- Add usage examples

## Best Practices

### Script Organization

1. **Location:**
   - Analysis scripts → `scripts/analysis/[therapeutic_area]/`
   - Utilities → `scripts/utils/`
   - MCP infrastructure → `scripts/mcp/`

2. **Naming:**
   - Descriptive: `obesity_pipeline_analysis.py`
   - Specific: `obesity_active_pipeline_analysis.py`
   - Consistent: `[condition]_[analysis_type].py`

3. **Path Handling:**
   - Use `Path(__file__).resolve()` for location-agnostic paths
   - Calculate root_dir dynamically
   - Add scripts/ to sys.path

4. **Documentation:**
   - README.md in each analysis subdirectory
   - Usage examples with expected output
   - Key findings summary

### Data Management

1. **Raw Results:**
   - Save to timestamped `data_dump/` directories
   - Include query parameters and metadata
   - Use descriptive directory names

2. **Analytical Outputs:**
   - Agent outputs → `temp/`
   - Timestamped filenames
   - Clear naming conventions

3. **Documentation:**
   - Testing docs → `docs/testing/`
   - User guides → `docs/`
   - Keep root clean (only README.md)

## Adding New Analysis Scripts

**Template:**

```python
#!/usr/bin/env python3
"""
[Description of analysis]
"""
import sys
import re
from pathlib import Path

# Add scripts directory to path
script_dir = Path(__file__).resolve().parent
root_dir = script_dir.parent.parent.parent
sys.path.insert(0, str(root_dir / 'scripts'))

from mcp.client import get_client

def extract_count(text):
    """Extract total count from MCP response"""
    match = re.search(r'(\d+) of ([\d,]+) studies found', text)
    return int(match.group(2).replace(',', '')) if match else 0

def main():
    client = get_client('[mcp-server-name]')

    # Analysis logic here

    print('=' * 100)
    print('[ANALYSIS TITLE]')
    print('=' * 100)

    # ... analysis phases ...

    print('\n' + '=' * 100)
    print('ANALYSIS COMPLETE')
    print('=' * 100)

if __name__ == '__main__':
    main()
```

**Checklist:**
- [ ] Script in correct `scripts/analysis/[area]/` directory
- [ ] Path handling uses `Path(__file__).resolve()`
- [ ] Uses MCP client pattern (`get_client()`)
- [ ] Includes `extract_count()` helper for CT.gov queries
- [ ] Structured output (header, phases, results, insights)
- [ ] README.md updated with usage and key findings
- [ ] Tested from multiple directories
- [ ] Results saved to `data_dump/`

## Maintenance

### Regular Tasks

1. **Clean data_dump/ periodically:**
   ```bash
   # Archive old analyses
   tar -czf archives/data_dump_$(date +%Y-%m).tar.gz data_dump/
   rm -rf data_dump/[old-dates]
   ```

2. **Update README files:**
   - Add new analyses to therapeutic area READMEs
   - Update key findings as data changes
   - Document new script patterns

3. **Organize temp/ outputs:**
   - Archive completed analytical outputs
   - Remove superseded analyses
   - Keep only current work

### Troubleshooting

**Script won't run from new location:**
- Check sys.path calculation
- Verify Path(__file__).resolve() logic
- Test from both root and script directory

**Import errors:**
- Ensure scripts/ is in sys.path
- Check MCP client availability
- Verify .mcp.json configuration

**Data organization issues:**
- Use consistent naming conventions
- Include timestamps in filenames
- Maintain clear directory structure

## Summary

**Key Principles:**
1. ✅ Scripts organized by function (`analysis/`, `utils/`, `mcp/`)
2. ✅ Therapeutic areas grouped in subdirectories
3. ✅ Location-agnostic path handling
4. ✅ Comprehensive documentation
5. ✅ Clean root directory (only README.md)
6. ✅ Timestamped data outputs
7. ✅ Consistent naming conventions

**Current Status:**
- Obesity analysis scripts: ✅ Organized
- MCP infrastructure: ✅ In place
- Utilities: ✅ Organized
- Documentation: ✅ Complete
- Root directory: ✅ Clean
